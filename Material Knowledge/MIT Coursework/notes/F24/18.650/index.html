<!doctype html>
<html>
    <head>
                <title>18.650 - Alex Zhao's Public Pages</title>

            <meta charset="utf-8">
            <meta http-equiv="X-UA-Compatible" content="IE=edge">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">

            
            
            

            
                <link  rel="icon" type="image/x-icon" href="../../../../../assets/favicon.ico">
            
                    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
                        <script>hljs.initHighlightingOnLoad();</script>
            <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Mono:400,700">
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
            <link rel="stylesheet" href="../../../../../assets/css/bootstrap.min.css">
            <link rel="stylesheet" href="../../../../../assets/css/main.min.css">
                <link href="../../../../../extra.css" rel="stylesheet">
                <script src="../../../../../extra.js"></script>
                <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
                <script src="../../../../../search/main.js"></script>

            
                
                     <style>:root {--text: var(--color-white);}</style> 
                     <style>:root {--title: var(--color-orange);}</style> 
                     <style>:root {--primary: var(--color-orange);}</style> 
                     <style>:root {--background: var(--color-black);}</style> 
                
            
    </head>

    <body>
        <div class="container py-3">
            <header>
                    <!-- block header -->
<nav class="navbar navbar-expand-xl border-bottom">
    <div class="container-fluid">
        

        
            <span class=" fs-4 title-color site-name" id="component-site-name" style="text-transform: uppercase;">Alex Zhao's Public Pages</span>
        

        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarsMenu"
            aria-controls="navbarsMenu" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse flex-column ml-auto" id="navbarsMenu">
            <ul class="navbar-nav">

                <!-- block menu -->
                <li class="nav-item">
                    <!-- block menu -->
    
        <li class="nav-item" id="component-menu">
            <ul class="navbar-nav">
                        <li class="nav-item">
                            <a class="
                            nav-link text-gray text-decoration-none" href="../../../../../Public%20Pages/homepage/">[Welcome]</a>
                        </li>
                        <li class="nav-item dropdown">
                            <a class="
                            nav-link dropdown-toggle text-decoration-none" href="#" data-bs-toggle="dropdown">[Crypto]</a>
                            <ul class="dropdown-menu">
                                    <!-- block dropdown-menu -->
    <li>
        <a href="../../../../../Material Knowledge/Sciences/Coding/Crypto/Proving Systems (Plonky3, Halo2, Circle STARKs, Binius).md" class="dropdown-item text-decoration-none ">ZK Notes</a>
    </li>
<!-- endblock -->
                            </ul>
                        </li>
                        <li class="nav-item dropdown">
                            <a class="
                            nav-link dropdown-toggle text-decoration-none" href="#" data-bs-toggle="dropdown">[Coding]</a>
                            <ul class="dropdown-menu">
                                    <!-- block dropdown-menu -->
    <li>
        <a href="../../../../Sciences/Coding/Vim%20Tricks/" class="dropdown-item text-decoration-none ">Vim Tricks</a>
    </li>
<!-- endblock -->
                                    <!-- block dropdown-menu -->
    <li>
        <a href="../../../../Sciences/Coding/USACO/General%20Thoughts%2C%20Paradigms/" class="dropdown-item text-decoration-none ">USACO Notes</a>
    </li>
<!-- endblock -->
                                    <!-- block dropdown-menu -->
    <li>
        <a href="../../../../Sciences/ML/ML%20papers%20to%20read/" class="dropdown-item text-decoration-none ">ML papers</a>
    </li>
<!-- endblock -->
                            </ul>
                        </li>
                        <li class="nav-item dropdown">
                            <a class="
                            nav-link dropdown-toggle text-decoration-none" href="#" data-bs-toggle="dropdown">[Food and Cooking]</a>
                            <ul class="dropdown-menu">
                                    <!-- block dropdown-menu -->
    <li>
        <a href="../../../../Food%2BCooking/%E5%AE%B6%E5%B8%B8%E8%8F%9C%E8%B0%B1/%E7%B3%96%E9%86%8B%E6%8E%92%E9%AA%A8/" class="dropdown-item text-decoration-none ">糖醋排骨</a>
    </li>
<!-- endblock -->
                            </ul>
                        </li>
            </ul>
        </li>
<!-- endblock -->
                </li>
                <!-- endblock -->

                <!-- block search -->
                <li class="nav-item">
                    <a class="collapsed" data-bs-toggle="collapse" href="#collapseExample" role="button" aria-expanded="false" aria-controls="collapseExample">
                        <div class="md-search-icon">
                            <i class="fa fa-search" aria-hidden="true"></i>
                        </div>
                    </a>
                </li>
                <!--  endblock -->

                <!-- block source -->
                <li class="nav-item">
                    
                </li>
                <!--  endblock -->
            </ul>
        </div>
    </div>
</nav>
<!--  endblock -->
            </header>

            <main><!-- block search -->
<div class="collapse" id="collapseExample">
    <div role="search" class="search-box">
        <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
            <input type="text" name="q" class="search-query"
            placeholder="Search docs" title="Type search term here" />
        </form>
    </div>
</div>
<!-- endblock -->
                    <!-- block content -->
<section class="container post">
    <article>
        <header>
            
                <h1 class=" title" id="component-title">18.650</h1>
            
        </header>
        <p><p>General idea: given samples from a distribution, we want to answer questions about the underlying distribution/predict the future.</p>
<p>Process goes:
- data, assumptions -&gt; model -&gt; predictions, declarations of uncertainty</p>
<p>Notes on moments:
- Variance is $\mathbb{E}[X^{2}]-\mathbb{E}[X]^{2},$ adds linearly over independent variables
- Covariance is $\mathbb{E}[XY]-\mathbb{E}[X]\mathbb{E}[Y],$ is 0 for indep. variables
- Covariance matrix $\Sigma$ satisfies $\Sigma_{ij}=\text{Covar}[X_{i},X_{j}],$ note that it is symmetric
- Can also think of $\Sigma$ as the expected value of the outer product of random vector $X$ with itself
- Hence $\Sigma^{-1/2}X$ is unit normal, since its outer product is $\Sigma^{-1/2}X X^{T}\Sigma^{-1/2}$  whose expected value is $I$</p>
<h2 id="distributions">Distributions</h2>
<ul>
<li><em>Multivariate Gaussian</em>—invert the covariance: $\frac{1}{\sqrt{ (2\pi)^{k}\det(\Sigma) }} \exp((x-\mu)^{\dagger}\Sigma ^{-1}(x-\mu)).$</li>
<li><em>Beta</em>—conjugate prior for Bayesian updates on Bernoulli parameter: $\text{Norm}\left[ x^{a}(1-x)^{b} \right]:x \in [0,1]$</li>
<li><em>Poisson</em>—models discrete distribution of event count in fixed time, limit of Binomial: $\frac{{\lambda^{k}e^{\lambda}}}{k!}$</li>
<li><em>Exponential</em>—time for an event to happen if each $dt$ is independent: $\frac{e^{-x/\lambda}}{\lambda}$ has eV $\lambda$</li>
<li><em>Gamma</em>—models time until $k$ rare events happen, i.e. sum of $k$ independent Exponentials: </li>
<li><em>Student-t</em>—fat version of Gaussian used when fitting model with unknown true variance, using sample variance</li>
<li><em>Chi-squared</em>—with $n$ degrees of freedom is sum of $n$ independent unit normal squared</li>
</ul>
<h3 id="clt">CLT</h3>
<p>If $X_{i}$ drawn from distribution with average $\mu$ and std $\sigma$ then the $n$th average $\bar{X}$ has mean $\mu$ and std $\frac{\sigma}{\sqrt{ n }}.$ We call the constant $\sigma$ the "asymptotic std".</p>
<p>If the sample averages for $X$ converge to mean $\mu$ and asymptotic std $\sigma$ then the sample averages for $g(X)$ converge to mean $g(\mu)$ and asymptotic std $g'(\mu)\sigma.$
This makes sense since as we grab more samples the density clusters around $\mu$ so we only care about the "stretching" behavior of $g$ local to $\mu.$ If $g$ spreads things out by a factor of $2$ then our linear unit, std., also stretches out by 2.</p>
<h2 id="parametric-estimation">Parametric Estimation</h2>
<h3 id="mle-fisher">MLE, Fisher</h3>
<p>Given data, we have a model $\mathbb{P}_{\theta}$ parametrized by a (usually finite) list of constants $\theta$. Given data we map it to an estimator $\hat{\theta}$ that can be judged from being
- <em>biased</em> (if its EV is different from true)
- has <em>se</em> (the std from true value)
- <em>consistent</em> (if it converges to true value in probability as we take many samples)
- <em>asymptotically normal</em> if as $n$ goes to infty it converges to being normal around true value with variance $\propto \,n^{-1/2}$.</p>
<p>We get an MLE estimator for all parameters by plugging in likelihood of drawing all of our data from the pdf formula, and maximizing log likelihood (take a derivative). It is asymptotically normal, consistent, and asymptotically efficient.</p>
<p>Note that true value maximizes <em>population log likelihood</em> i.e. log likelihood over the population, because log likelihood is really just KL divergence from true distribution to our proposed distribution. The sample MLE maximizes <em>sample log likelihood</em>.</p>
<h4 id="fisher-info">Fisher info</h4>
<p>Given a model $f_{\theta}$ and a particular value for $\theta,$ the Fisher information is
$$
I(\theta):=\mathbb{E}<em>{\theta}[-\nabla^{2}</em>{\theta}\log f_{\theta}(X)]=\mathbb{V}<em>{\theta}[\nabla \log f</em>{\theta}(X)],
$$
when drawing a random $X$ from the distribution $f_{\theta}$.</p>
<p>To check the second equality, note that
$$
-\nabla^{2}\log f_{\theta}=-\nabla\frac{{\nabla f_{\theta}}}{f_{\theta}}=-\frac{{\nabla^{2}f_{\theta}f_{\theta}-(\nabla f_{\theta}^{2})}}{f_{\theta}^{2}}=\left( \frac{{\nabla f_{\theta}}}{f_{\theta}} \right) ^{2} - \frac{{\nabla^{2}f_{\theta}}}{f_{\theta}}.
$$
But then $\mathbb{E}\left( \frac{{\nabla g}}{f_{\theta}} \right)=\int \nabla g=0,$ so $\mathbb{E}[-\nabla^{2}\log f_{\theta}]=\mathbb{V}[\nabla \log f_{\theta}].$</p>
<p>Key claim: asymptotic std of the MLE estimator is $I(\theta^{*})^{-1}.$</p>
<p>Proof:
Taylor expand
$$
0=l_{n}'(\theta)\approx l_{n}'(\theta^{<em>})+l''_{n}(\theta^{</em>})(\hat{\theta}-\theta^{<em>}),
$$
so that
$$
\sqrt{ n }(\hat{\theta}-\theta^</em>)=-\frac{{\sqrt{ n }\overline{\partial_{\theta}  \log f_{\theta}{(X_{i})|_{\theta ^<em>}} } }}{\overline{\partial^{2}<em>{\theta}\log f</em>{\theta}(X_{i})|_{\theta^</em>}}}.
$$
The numerator has expected value $0$ since $l'(\theta^<em>)=0,$ and variance equal to $I(\theta^</em>).$ The denominator converges to its mean value, also equal to $I(\theta^<em>).$ Hence the quotient has mean $0$ and variance $I(\theta^</em>)^{-1}.$</p>
<h3 id="method-of-moments">Method of Moments</h3>
<p>Given $k$ real parameters $\theta$ that we want to solve for, we plug in for the first $k$ moments of our model $f_{\theta}(X).$ Then we can express the $i$th moment in terms of our $k$ parameters, and we solve the resulting $k$ equations.</p>
<p>Remark: we could take higher order moments, but they would yield higher variance answers, since higher moments "swing around" more.</p>
<h3 id="em-algo">EM Algo</h3>
<p>Used for mixture models. If we already knew which Gaussian each data sample is from, we can normal MLE in order, first by estimating $\mu,\sigma$ for each Gaussian and then balancing $p_{i}.$</p>
<p>However if we don't know, we need to assign a probability distribution of which Gaussian each element is in. Then the log likelihood for a given datapoint is $\sum_{i}p_{i}l_{i}(X),$ where $p_{i}$ is the likelihood of belonging to the $i$th Gaussian.</p>
<p>Bring in the EM-algorithm. On the <em>Expectation step</em> we weight the odds of $p_{i}$ by comparing odds according to the current $\mu_{i},\sigma_{i}.$ On the <em>Maximization step</em> we calculate the $\mu_{i},\sigma_{i}$ exactly using MLE and weighted log probs according to $p_{i}$.</p>
<h3 id="bootstrap">Bootstrap</h3>
<p>We want to get variance on our estimator, but the underlying pdf is intractable. Instead, we "repeat the experiment" by taking <em>bootstrap samples</em> from our existing samples <em>with replacement</em>.
1. For each sample we compute our estimator, then we create a histogram of drawn estimators from which we can compute variance, confidence intervals, etc.
2. We can do normal confidence interval by taking std and assuming distribution is normal, or we can take <em>percentile confidence interval</em> which just takes quartiles using our histogram.
3. Finally we can take <em>pivotal confidence interval</em> $\left( 2\hat{\theta}<em>{0}-q</em>{\frac{\alpha}{2}}, 2\hat{\theta}<em>{0}-q</em>{1-\frac{\alpha}{2}}  \right)$ because we want true to lie within a certain range of our estimate, not vice versa (??) so we flip the interval around $\hat{\theta_{0}}.$
Optimally we do all $n^{n}$ random samplings with replacement but this is not actually feasible.</p>
<h3 id="linear-regression">Linear Regression</h3>
<p>Given vectors $X_{i}$ we want to map to scalars $Y_{i}.$ We assume our distribution is $f(X)=\mathcal N(X\beta ^{T}, \mathbf{1}).$ Then MLE just wants us to minimize least-squares distance between $X\beta$ and $Y,$ where we now take the matrix $X$ and vector $Y.$ Here the rows of $X$ are the vectors $X_{i}.$</p>
<p>We can take gradients to solve the minimization problem
$$
L=\left( X\beta-Y \right) \cdot \left( X\beta-Y \right) = \beta^{T}X^{T}X\beta-2Y^{T}X\beta.
$$
Then
$$
\nabla_{\beta} L=2X^{T}X\beta - 2Y^{T}X,
$$
so
$$
\beta=(X^{T}X)^{-1}X^{T}Y.
$$
Now note that our "closest solution" $X\beta=X(X^{T}X)^{-1}X^{T}Y$ is in fact the result of projecting $Y$ down to $\text{colspace}(X).$ Clearly the output of
$$P=X(X^{T}X)^{-1}X^{T}$$
is in $\text{colspace}(X),$ and since $P^{2}=P^{T}=P$ we get $P(I-P)^{T}=0$ and so projections onto $\text{colspace}(X)$ are in fact normal. Define $\mathbb{X}$ as the matrix with $X_{i}^{\dagger}$ as rows.</p>
<h4 id="variance-on-linear-regression">Variance on Linear Regression</h4>
<p>Suppose our (independent) $Y$ have (diagonalized) variance $\sigma^{2}.$ Then we can model $Y=X\beta^*+\epsilon$ where $\epsilon\sim\mathcal N(0,\sigma).$ Plugging back into our expression for $\beta$ we get that
$$Var(\beta)=\sigma^{2}((X^{T}X)^{-1}X^{T})((X^{T}X)^{-1}X^{T})^{T}=\sigma^{2}(X^{T}X)^{-1}.$$
Note that $\sigma^{2}$ commutes because it's diagonalized. As an operational note we often use $\sigma^{2}=\frac{{\lVert Y-X\beta \rVert^{2}}}{n-k}$ as our error estimate.</p>
<h3 id="logistic-regression">Logistic Regression</h3>
<p>We want to predict a binary, or more generally a multiclass, i.e. what is the likelihood $Y$ will happen given $X$? This is very machine-learning style! We get $\sigma(x^{T}\beta)$ as our model, where $x^{T}\beta$ outputs a bunch of logits. We can then do softmax to get our probabilities, and perform MLE on the matrix.</p>
<p>Statisticians will insist we conserve degrees of freedom, so our softmax just sets $l_{0}=0$ and only predicts the latter $m-1$ logits. Note that this is consistent with using sigmoid for binary classification.</p>
<h3 id="r-squared">R squared</h3>
<p>The $R^{2}$ score is
$$
R^{2}(S)=1-\frac{{\lVert Y-X\beta(S) \rVert ^{2}}}{\lVert Y-\bar{Y}\mathbb 1 \rVert^{2} }.
$$
The denom is squared distance from $Y$ to the line spanned by $\mathbb{1},$ (also equals $Var(Y)$), i.e. performance if we make our model just the mean. It becomes negative when the $X$ features predict worse than the mean.</p>
<h3 id="feature-selection">Feature selection</h3>
<p>Generally adding more features to input data $X$ will allow model to fit better (e.g. project closer, eventually memorize data) but this is bad. We can pick features that increase $R^{2}$ the fastest, but don't include all to avoid overfit. Can do beam search and look for some plateau.</p>
<p>We can also measure overfitting using information. 
- Akaike info: $l_{n}(\hat{\beta}(S))-|S|$
- Bayesian info: $l_{n}(\hat{\beta}(S))-\frac{{\log n}}{2}|S|$</p>
<h2 id="nonparametric-estimation">Nonparametric Estimation</h2>
<p>Goal: estimating curves/distributions without setting an ansatz and solving.</p>
<p>Generally we have some true distribution $g$ generating noisy samples $X$ which we fit to an estimator $X_{i}\to \hat{g}.$ Then (taking expectations over samples, for conf. interval purposes)
- <em>bias</em> is how far estimator mean is from truth, for some input $x$
- <em>variance</em> is variance of estimator from its own mean
- <em>mean squared error</em> is actual optimization point, MSE of estimator from ground truth
Note that $MSE(\hat{g},x)=b_{\hat{g}}^{2}(x)+v_{\hat{g}}(x).$ We define $R(\hat{g},g)=\int MSE(\hat{g},x)\,dx$ as error over the entire input. Also called mean integral squared error.</p>
<p>For optimization purposes we want to check the MISE, reduces to $\int g(x)\hat{g}(x)\,dx=\mathbb{E}_{x\sim g} \int \hat{g}(x).$ Since $\hat{g}$ depends on chosen $x$ we just split train/test, textbook suggests to run all of the $n-1 / 1$ train-test splits.</p>
<p>Can estimate using
- histograms (box samples and make uniform in each box) called <em>Regressogram</em>
- kernel density estimators (put a blob on each sample, fix variance to $h^{2}$ with reparameterization, mean over samples) called <em>Nadaraya-Watson</em></p>
<p>If we want to do regression we have a distribution over pairs $X,Y.$ Can apply either technique—would be taking kernels in $X\oplus Y$ and taking probabilities over fixed $X$.</p>
<h2 id="testing">Testing</h2>
<p>Have null hypothesis, which we take to be status quo. Assume null hypothesis, what is the likelihood of seeing given data? Call that $p$-value, determines the level of our test. Type 1 error is false positive, Type 2 error is false negative.</p>
<p>The "power" of a test is likelihood of rejecting null, defined by $\beta(\theta).$ If $H_{0}: \theta=\theta_{0},$ then likelihood of type 1 (rejecting when shouldn't reject) is $\beta(\theta_{0}).$</p>
<h3 id="wald-test">Wald test</h3>
<p>Asymptotically normal estimator $\hat{\theta},$ we return positive iff outside percentile confidence interval.</p>
<p>Specifically, take sample mean and we know the variance. If null is interval then $p$-value is likelihood of falling in that interval. If null is equals some value then $p$-value is likelihood of being at least as far as that value.</p>
<h3 id="chi-squared-goodness-of-fit">Chi-squared goodness-of-fit</h3>
<p>Define $\chi_{k}^{2}=\sum_{i.i.d.}^{k}Z_{i}^{2},$ where $Z_{i}\sim \mathcal N(0,1).$ Then given drawn samples $X_{i}$ and null hypothesis pmf, we can count real and expected occurrences of each outcome. Then the value
$$
T=\sum_{i}\frac{{(O_{i}-E_{i})^{2}}}{E_{i}}
$$
follows a $\chi_{k-1}^{2}$ distribution.</p>
<p>Proof: Let our samples $X_{i}$ be represented as one-hot encodings in our pmf. Then null hypothesis is that
$$
\Sigma=\begin{bmatrix}
p_{1}(1-p_{1})&amp;-p_{1}p_{2}&amp;-p_{1}p_{3} \
-p_{2}p_{1}&amp;p_{2}(1-p_{2})&amp;-p_{2}p_{3} \
-p_{3}p_{1}&amp;-p_{3}p_{2}&amp;-p_{3}(1-p_{3})
\end{bmatrix}
=
-\vec{p}\otimes \vec{p}+diag(\vec{p}).
$$
Let's remove the last row/column to get $\hat{\Sigma}$. Then letting $\hat{p}$ denote the truncated probability vector, notably
$$
\hat{\Sigma} ^{-1}=diag(\hat{p}^{-1})+\frac{1}{p_{k}}\begin{bmatrix}
1 &amp; \dots&amp;1 \
\vdots &amp;\ddots &amp;\vdots\
1 &amp; \dots&amp;1 \
\end{bmatrix}
$$
To check this, off diagonal dot products $M_{ij}$ of $\hat{\Sigma}\hat{\Sigma}^{-1}$ become $-p_{i}+\frac{1}{}$ $\textcolor{red}{TODO}$</p>
<h3 id="kl-and-ks-tests">KL and KS Tests</h3>
<p>Given iid samples from a fixed pdf, we can use Kolmogorov-Smirnov. We can generate an <em>empirical CDF</em> generated from uniform over our samples. The sup of the difference between our empirical CDF and the real CDF is distributed according to the KS distribution, dependent on $n$ but not dependent on the distribution!</p>
<p>In the case that it's a Gaussian whose $\mu$ and $\sigma$ we derive from the sample, we need to use the Kolmogorov Lilliefors test, which requires a smaller distance to reject the null (because the Gaussian is already fitted to the data).</p>
<h3 id="permutation-multiple-hypothesis">Permutation, Multiple Hypothesis</h3>
<p>Are two samples from the same distribution? Bootstrap-style, mix them up and take a histogram of the difference in sample means. If the difference in means of our two samples are too far OOD then reject.</p>
<p>For multiple hypothesis, we can take a naive union bound over all our hypothesis, dividing the $p$-value for each test by the number of tests (Bonferroni).</p>
<p>Alternatively if they're guaranteed to be independent, the Benjamini-Hochberg method sorts the $p$-values in order, and taking the biggest one that lies below $\frac{\alpha}{m}i$ (where $i$ is the index of $p$-value) keeps (#false positives)/(#positives) below $\alpha$ in expectation.</p>
<h3 id="student-t">Student-t</h3>
<p>Smarter version of Wald's. It compensates for not knowing the std $\alpha$. Specifically $\sqrt{ n }(\bar{X}<em>{n}-\mu)\hat{\sigma}\sim t</em>{n-1}$ for $n-1$ DOF.</p>
<h3 id="things-to-rem">Things to Rem.</h3>
<p>Within 1 std: 68%
Within 2 std: 95%
Within 3 std: 99.7%</p>
<h3 id="distributions_1">Distributions</h3>
<p><em>Beta</em>: $p(x)=\frac{1}{K}x^{a-1}(1-x)^{b-1}$ for $Beta(a,b).$ Expected value $\frac{a}{a+b}.$</p>
<h2 id="bayesian">Bayesian</h2>
<p>We have a prior distribution on parameters $\theta.$
After seeing data we adjust the distribution based on a conditional. The net effect is that the posterior is the likelihood of seeing this data, weighted by the prior:
$$
f(\theta|X_{i})\propto f_{\theta}(X_{i})\cdot f(\theta).
$$
If we start with uniform over $\mathbb{R}$ or some interval $[a,b]$ then this is equivalent to MLE.</p>
<h3 id="estimators">Estimators</h3>
<p>Bayes estimator is just the mean of our posterior, i.e. mean <em>a posteriori</em>. MAP, or maximum a posteriori, is the mode of our posterior.</p>
<h3 id="aside-robustness">Aside: Robustness</h3>
<p>An estimator is <em>robust</em> if it stays bounded when an adversary changes some amount of it. For instance median is robust with breakdown point $\frac{1}{2}.$ We can arbitrarily make an estimator more robust by dropping the top and bottom percentiles.</p>
<p>More robust estimators do MLE assuming that $\epsilon$ of our samples have been contaminated by an adversary $q$. We can also try omitting samples, i.e. calculate MLE by maximizing $l_{n}$ over all possible omission sets, and then maximize $\theta$ to get a double max:
$$
\hat{\theta}={\arg\max}<em>{\theta}\max</em>{|C|=m}l_{n}(\theta,X_{i}\backslash C).
$$</p>
<h2 id="confounding-setups">Confounding Setups</h2>
<h3 id="survivalcensoring">Survival/Censoring</h3>
<p>Sometimes we want to collect samples $T_{i}$ but they get "cut off" arbitrarily at $C_{i}$, independent of the statistic. How to estimate the cdf?</p>
<p>Derive a "harm" estimator $h(t):=\Pr(T_{i}=t\mid T_{i}\geq t)$. Then we can directly count these from taking all $C_{i}&gt;t$ and computing
$$
\frac{{# T_{i}=t}}{# C_{i}, T_{i} \geq t}.
$$
Then $\Pr(T_{i}&gt; t)=\prod_{i\leq t} (1-h(t)).$</p>
<h3 id="randomized-controlled-trials">Randomized Controlled Trials</h3>
<p>We have people $i$ with treatment applied or unapplied $X_{i}$ and reward distribution $C_{X}$ for each person. Aim: general effect of application
$$\theta=\mathbb{E}[C_{1}] - \mathbb{E}[C_{0}].$$
However for each sample we only get to see $C_{X},$ so if we just make $X$ independent of the "person" (since $C_{i}$ is dependent on the person) then we get
$$
\theta=\alpha:=\mathbb{E}[C_{1}\mid X=1] - \mathbb{E}[C_{0}\mid X=0].
$$</p>
<h3 id="surveys">Surveys</h3>
<p>We want to know $T:=\sum_{i}Y_{i}$ over the entire body, but can only grab $\sum_{i\in S}Y_{i}$ for some random $S$. Then the Horvitz-Thompson estimator is
$$
T^{HT}:=\mathbb{E}\left[ \sum_{i\in S} \frac{Y_{i}}{\pi(i)} \right]=\sum_{i} \frac{Y_{i}}{\pi(i)}\Pr(i\in S)=\sum_{i}Y_{i}.
$$
Can evaluate the variance in theory using $\pi_{ij},$ then apply Horvitz-Thompson on this by dividing by $\pi_{ij}$ again.</p>
<h3 id="classification">Classification</h3>
<p>Given inputs $X$ want to classify into labels $Y\in \left{ 0,1 \right}.$ We find a "Bayes estimator"
$$
h:=\arg\max_{h} \Pr[Y \neq h(X)].
$$
Equivalently, $h=1$ if $r(x):=\mathbb{E}(Y|X=x)\geq \frac{1}{2}$. Can also do if $\frac{\Pr(X=x|Y=1)}{\Pr(X=x|Y=0)} \geq \frac{{\Pr(Y=0)}}{\Pr(Y=1)},$ hence called Bayes.</p>
<p>In high dimensions naive KDE isn't great, so can either
- naively partition input dimensions into independent subsets
- assume $X|Y=i$ are Gaussian, obtain a quadratic classifier
Can also classify by mean of $k$ nearest neighbors, can be represented using KDE (look at "effective range" of each node).</p></p>
    </article>
</section>
<!-- endblock -->
            </main>

            
                    <!-- block preview -->
<!-- endblock -->
            

            
                    <!-- block footer -->
<footer class="pt-4 my-md-5 pt-md-5 border-top" id="component-footer">
    <div class="row">
        <div class="col-12 col-md">
                <!-- block copyright -->

    <small class="d-block mb-3">
        Made with
        <a href="https://github.com/FernandoCelmer/mkdocs-simple-blog" target="_blank" rel="noopener">
            Simple Blog for MkDocs
        </a>
    </small>

<!-- endblock -->
        </div>
    </div>
</footer>
<!-- endblock -->
            
        </div>

            <script>var base_url = '../../../../..';</script>
            <script src="../../../../../assets/js/jquery-3.3.1.slim.min.js""></script>
            <script src="../../../../../assets/js/bootstrap.bundle.min.js""></script>
            <script src="../../../../../assets/js/main.min.js""></script>
                <script src="../../../../../extra.js" defer></script>
                <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" defer></script>
                <script src="../../../../../search/main.js" defer></script>

    </body>

</html>