## Problem 1
### (a)
No, they cannot. If they form a LRT, the $P_{F}$ and $P_{D}$ must form a concave plot when graphed, however these values do not satisfy that; the slope of each of the segments when $P_{F}$ is graphed on the $y$-axis is $\frac{1}{4}, 4, \frac{1}{4}$ in order, which doesn't work.
### (b)
The likelihood $P_{e}$ is
$$
P_{e}=P_{F}\cdot p(H_{0}) + (1-P_{D})\cdot p(H_{1}).
$$
Then for $\gamma=0$ we get $P_{e}=\frac{2}{3},$ for $\gamma=1$ we get $P_{e}=\frac{11}{15},$ for $\gamma=2$ we get $P_{e}=\frac{4}{15}$ and for $\gamma=3$ we get $P_{e}=\frac{1}{3}.$
### (c)
Note that
$$P_{F}(\gamma)=\mathbb P[\hat{H}(y)=H_{1}\mid H_{0}] = \mathbb P[y \geq\gamma\mid H_{0}].$$ 
Similarly,
$$
P_{D}(\gamma)=\mathbb P[\hat{H}(y)=H_{1}\mid H_{1}]=\mathbb  P[y \geq \gamma \mid H_{1}].
$$
Hence the $P_{F}$ and $P_{D}$ are like "reverse CDFs" of the PDFs. In particular, under $H_{0}$ we get $0.1$ chance $y=0,$ $0.8$ chance $y=1$, $0.1$ chance $y=2.$ Since $P_{F}(0)=1$ and $P_{F}(3)=0$ $y$ can hit no other values under $H_{0}$.

Similarly, under $H_{1}$ we get $0.4$ chance $y=0,$ $0.2$ chance $y=1,$ and $0.4$ chance $y=2.$
### (d)
By using the coin, we can take any midpoint of two existing $P_{F},P_{D}$ points. Hence the points we can take are
$$
(0,0),(0.05,0.2),(0.1,0.4),(0.45,0.3),(0.5,0.5),(0.55,0.7),(0.9,0.6),(0.95,0.8),(1.1).
$$
### (e)
Because we have a prior $p(H_{1})=\frac{1}{3}$ on the probability of $H_{0}$ vs $H_{1},$ we can use the Bayesian test on the likelihood ratio. Specifically, since error minimization involves costs $1,1$ we get odds $2:1$ favoring $H_{0},$ and so our cutoff is $\eta=2.$ The ratios for $y=0,1,2$ are $4, \frac{1}{4}, 4$ respectively, so pick $H_{1}$ if $y=0,2$ and $H_{0}$ otherwise.
## Problem 2
### (a)
We want to minimize $\eta P_{F}-P_{D},$ where $\eta=\rho.$ In other words, we want to find the "northmost" tangent line with slope $\rho$. Note that the "convex features" are at $(0,0.5)$ and $(0.5,1)$ so for $\rho<1$ we want to use the blue curve corresponding to $u=2,$ and for $\rho>1$ we want to use the red curve corresponding to $u=1.$
### (b)
Take the frontier of the convex hull of all achievable points from the blue or red curves. We get a frontier composed of two line segments, from $\left( 0, \frac{1}{2} \right)\to\left( \frac{1}{2}, 1 \right)\to (1,1).$ Obviously once we reach $P_{D}=1$ there is no reason to continue increasing $P_{F}.$

For $P_{F}\in\left( 0, \frac{1}{2} \right),$ we need to randomize $u$ between $1$ and $2,$ picking $u=2$ with probability $p=2P_{F}$ in order to interpolate smoothly from $p=0$ to $p=1$ for $P_{F}\in\left( 0, \frac{1}{2} \right).$ For $P_{F}=0$ we always pick $u=1$ and for $P_{F}\geq \frac{1}{2}$ we always pick $u=2.$
### (c)
No. Minimizing the error of probability is equivalent to minimizing $p(1-P_{D})+(1-p)(P_{F}),$ where $p$ is the prior for $H_{1}$. Randomization only allows you to take affine combinations of operating points permissible by the existing rules. Hence, regardless of the set of usable decision rules, we cannot get a new best error probability by randomizing our decision rule.
## Problem 3
### (a)
The LRT rule can be expressed as
$$
\frac{{2e^{-2y}}}{e^{-y}} \underset{\hat{H}=H_0}{\overset{\hat{H}=H_1}{\gtreqless}} \gamma'
$$
or
$$
2e^{-y} \underset{\hat{H}=H_0}{\overset{\hat{H}=H_1}{\gtreqless}} \gamma'
$$
or
$$
-y \underset{\hat{H}=H_0}{\overset{\hat{H}=H_1}{\gtreqless}} \ln \left( \frac{\gamma'}{2} \right) 
$$
or
$$
y \underset{\hat{H}=H_1}{\overset{\hat{H}=H_0}{\gtreqless}} -\ln \left( \frac{\gamma'}{2} \right) =\gamma.
$$
For a given $\gamma$,
$$
P_{F}=\mathbb P(y \leq \gamma | H_{0})=\int_{0}^{\gamma}e^{-y}=1-e^{-\gamma},
$$
$$
P_{D}=\mathbb P(y \leq \gamma | H_{1})=\int_{0}^{\gamma}2e^{-2y}=1-e^{-2\gamma},
$$
and hence $P_{D}=1-(1-P_{F})^{2}=2P_{F}-P_{F}^{2}.$
### (b)
We want $\eta=\gamma'$  to equal $\frac{(1-p)C_{10}}{pC_{01}}$, hence the $\gamma$ in our decision rule on $y$ should equal $-\ln \left(  \frac{(1-p)C_{10}}{2pC_{01}} \right).$
### (c)
For a given $r$ the likelihood of $H_{0}$ is $\frac{1}{r+1}$ and likelihood of $H_{1}$ is $\frac{r}{r+1}.$ Let $p=\frac{r}{r+1}.$ Note that this is strictly monotonic in $r$ and $p$ ranges from $0$ to $1.$

For a given $p$ the expected costs associated with each choice are:
- $H_{0}$: $p C_{01}$
- $H_{-}$: $pC_{-1}+(1-p)C_{-0}$
- $H_{1}:$ $(1-p)C_{10}$
We can plot these cost lines, and then the best possible performance is the pointwise minimum over these three lines. Then our choice for each $p$ is determined by which line the best choice lies on.

The case for $-$ is when
$$
pC_{-1}+(1-p)C_{-0}\leq pC_{01}, (1-p)C_{10}
$$
i.e.
$$
(1-p)C_{-0}\leq p(C_{01}-C_{-1}),\quad  pC_{-1}\leq (1-p)(C_{10}-C_{-0})
$$
i.e.
$$
\frac{C_{-0}}{C_{01}-C_{-1}}\leq r=\frac{p}{1-p}\leq \frac{{C_{10}-C_{-0}}}{C_{-1}}.
$$
$H_{0}$ is better than $H_{1}$ iff $pC_{01}\leq (1-p)C_{10},$ i.e. $r \leq \frac{C_{10}}{C_{01}}.$

Hence we pick $H_{0}$ if $r\leq \frac{C_{10}}{C_{01}}, \frac{C_{-0}}{C_{01}-C_{-1}}$, we pick $H_{-}$ if $\frac{C_{-0}}{C_{01}-C_{-1}}\leq r\leq \frac{{C_{10}-C_{-0}}}{C_{-1}},$ and we pick $H_{1}$ if $\frac{{C_{10}-C_{-0}}}{C_{-1}}, \frac{C_{10}}{C_{01}} \leq r.$

Hence $u=\frac{C_{10}}{C_{01}}, v=\frac{C_{-0}}{C_{01}-C_{-1}},w= \frac{{C_{10}-C_{-0}}}{C_{-1}}.$
### (d)
Take any selective classifier $\hat{H}',$ and define $\hat{H}''$ that rules $H_{0}$ in all cases when $\hat{H}'$ rules $H_{-}.$ Then $\hat{H}'$ and $\hat{H}''$ rule $H_{1}$ on the exact same set of events, hence they have identical $P_{F}$ and $P_{D}.$ Since $\hat{H}''$ is subject to the bound in part (a), so must $\hat{H}',$ and so any selective classifier cannot achieve a better $P_{D}$ for any given $P_{F}$ than the given $\zeta_{NP}$ in part (a).
## Problem 4
### (a)
For $y\in(0,1)$ we only know that $x$ is uniform in $[0,1]$ so our best estimate is $x=\frac{1}{2}.$ Otherwise $y\in(-1,0)$ and $x$ is uniform in $[-1,1]$ so our best estimate is $x=0.$
### (b)
Equivalent to variance of uniform in $[0,1]$ and uniform in $[-1,1].$
### (c)
For $y\in(0,1)$ we still know $x$ is uniform in $[0,1]$ so we can ignore the piecewise cost, and the best estimate is still $x=\frac{1}{2}.$ (Our cost is just $K(\hat{x}-x)^{2},$ which is still proportional to the usual square error cost.)

For $y\in(-1,1)$ we know $x$ is uniform in $[-1,1]$ but our cost is $(\hat{x}-x)^{2}$ in the negative regime and $K(\hat{x}-x)^{2}$ otherwise. Then our goal is to minimize
$$
\begin{align*}

\mathbb E(C(x,\hat{x}))
&=\frac{1}{2}\left( \int_{-1}^{0}(\hat{x}-x)^{2}dx+\int_{0}^{1}K(\hat{x}-x)^{2}\,dx \right) \\
&=\frac{1}{2}\left( \left( \hat{x}^{2}+\hat{x}+\frac{1}{3} \right) +K\left( \hat{x}^{2}-\hat{x}+\frac{1}{3} \right) \right) \\
&= D + \frac{1}{2}\left( (K+1)\hat{x}^{2}+(1-K)\hat{x} \right) 
\end{align*}
$$
for some constant $D,$ hence the correct value for $\hat{x}$ is $\frac{{K-1}}{2(K+1)}.$
## Problem 5
### (a)
By directly applying max-min we get
$$
\begin{align*}
\max_{p_{x}}\min_{\hat{x}}\int p_{x}(x)\mathbb E[C(x,\hat{x}(y))]\,dx
&\leq \min_{\hat{x}}\max_{p_{x}}\int p_{x}(x)\mathbb E[C(x,\hat{x}(y))]\,dx.
\end{align*}
$$
Consider (one of) the value(s) of $x_0$ for which $\mathbb E[C(x,\hat{x}(y))]$ is maximized. Then
$$
\int p_{x}(x)\mathbb E[C(x,\hat{x}(y))]\,dx= \mathbb E_{p_{x}}[\mathbb E_{p_{y}}[C(x,\hat{x}(y))]].
$$
is maximized when $p_{x}$ is deterministic and returns $x_{0}.$ Hence 
$$
\max_{p_{x}}\int p_{x}(x)\mathbb E[C(x,\hat{x}(y))]\,dx=\max_{{x}}\mathbb E[C(x,\hat{x}(y))],
$$
and we get the desired.
### (b)
Directly applying the Bayes' estimator definition yields
$$
\min_{\hat{x}}\int p_{x}(x) \mathbb E_{p_{y}}[C(x,\hat{x}(y))]\,dx
=\int p_{x}(x) \mathbb E_{p_{y}}[C(x,\hat{x}_{B}(y))]\,dx
=\max_{x} \mathbb E_{p_{y}}[C(x,\hat{x}_{B}(y))]\,dx.
$$
But then by part (a) we know that
$$
\begin{align*}
\max_{x} \mathbb E_{p_{y}}[C(x,\hat{x}_{B}(y))]\,dx
&\geq \min_{\hat{x}} \max_{x} \mathbb E_{p_{y}}[C(x,\hat{x}(y))]\,dx\\
&\geq \max_{p_{x}}\min_{\hat{x}} \int p_{x}(x) \mathbb E_{p_{y}}[C(x,\hat{x}(y))]\,dx\\
&\geq  \min_{\hat{x}}\int p_{x}(x) \mathbb E_{p_{y}}[C(x,\hat{x}(y))]\,dx\\
&=\max_{x} \mathbb E_{p_{y}}[C(x,\hat{x}_{B}(y))]\,dx.
\end{align*}
$$
Hence all of these expressions must be equal, and so the given $p_{x}$ achieves the cost given by the maximin problem given in part (a) and so is a least favorable prior. Then the Bayes estimator $\hat{x}_{B}$ for the least favorable prior is the minimax estimator.
### (c)
If $f(x):=\mathbb E_{p_{y}}[C(x,\hat{x}_{B}(y))]\,dx$ is constant in $x$ for the Bayesian estimator with respect to some $p_{x}',$ then we can take any distribution $p_{x}$ and then
$$
\int p_{x}(x)f(x)dx=\int p_{x}(x)f(0)dx=f(0)\int p_{x}(x)dx=f(0)=\max_{x}f(x).
$$
Hence we can apply part (b), and we get that $\hat{x}_{B}$ is the minimax estimator. We also get as a corollary that *any* prior is a least favorable prior, i.e. our adversary gets no advantage by intelligently choosing a prior.