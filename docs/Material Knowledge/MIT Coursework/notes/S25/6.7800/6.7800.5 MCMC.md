Oftentimes distributions are hard to compute. More or less it's because some integral is difficult; if we want to do a conditional $p(y|x)$ have to compute the joint $p(x)$ which can be hard. Generally joints, log partitions, direct sampling from conditionals, etc.

Then we want:
- *Importance sampling*. To compute an EV, weight samples by their "normalized odds", i.e. sampling a mean from unnormalized $p,$ weight averages by $\frac{q}{p}$ if sampling from unnormalized $q.$
- *Rejection sampling*. Similar to above, except we also need an upper bound (can't deal with odds > 1). Accept with probability $\frac{p}{q}.$

Monte Carlo is when you sample to try and solve a problem. Use a Markov Chain to sample!

Set up a Markov Chain to have stable distribution equalling target distribution. Do this with *Metropolis-Hastings*:
- Finitely many states, fully-communicating, not always acceptance 1, reversibility (conditioning on $X_{n-1}$ or $X_{n+1}$ yields same distribution for $X_{n}$)
- Have initial state and proposal distribution $v(\cdot|x),$ and accept transition with probability $\min\left( 1, \frac{p(x')v(x|x')}{p(x)v(x'|x)}  \right).$
- Works and is reversible because going one way, kernel likelihood is $\frac{p(y)v(x|y)}{p(x)},$ the other way is $v(x|y).$ Ratio of kernel transitions equals ratio of desired stable distribution.