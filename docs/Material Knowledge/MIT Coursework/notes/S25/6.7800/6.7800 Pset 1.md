## Problem 1.1
### (a)
#### (i)
The probability that $s=s_{0}$ is
$$
p_{s}(s_{0})=\sum_{x_{0}=0}^{s_{0}}p_{x}(x_{0})p_{y}(s_{0}-x_{0})=\sum_{x_{0}=0}^{s_{0}}p^{2}(1-p)^{s_{0}}=(s_{0}+1)p^{2}(1-p)^{s_{0}}.
$$
The graph of $p(s)$ limits to 0, starts at $p^{2},$ but initially doesn't fall off as quickly as $p(x)$ or $p(y)$.
#### (ii)
As computed above, any pair of $x,y$ summing to a given $s_{0}$ is equally probably (occurring with likelihood $p^{2}(1-p)^{s_{0}}$) so it's uniform over $0,1,\dots,s_{0}.$
#### (iii)
The average of uniform over $0,1,\dots,s_{0}$ is $\frac{s}{2}.$
#### (iv)
This is exactly equal to half of the random variable $s$ so this PMF hits all $\frac{n}{2}$ for nonnegative integers $n$ with probability $(n+1)p^{2}(1-p)^{n}.$
# Problem 1.2
### (a)
Integrate over all possibilities for $x,y$. Namely
$$
\begin{align*}
\iint_{x^{2}+y^{2}\leq \sigma^{2}} \frac{1}{2\pi\sigma^{2}} e^{-(x^{2}+y^{2})/2\sigma^{2}}\,dxdy
&= \iint_{r\leq\sigma} \frac{1}{2\pi\sigma^{2}}e^{-r^{2}/2\sigma^{2}}r\,dr d\theta\\
&= \frac{1}{2\pi\sigma^{2}}\cdot 2\pi \cdot \int_{0}^{\sigma}re^{-r^{2}/2\sigma^{2}}\,dr\\
&=\frac{1}{\sigma^{2}} \cdot \left. -\sigma^{2}e^{-r^{2}/2\sigma^{2}} \right|_{0}^{\sigma }\\
&= 1-e^{-1/2}.
\end{align*}
$$
### (b)
The two likelihoods—that $x\geq_{}0$ and $y\geq 0$—are independent, so we get $\frac{1}{4}.$
### (c)
Since the two likelihoods are independent (by rotational symmetry) we get the same answer as that from part (a), i.e. $1-e^{-1/2}.$
### (d)
We take the differential $dxdy=r dr d\theta.$ Since $p_{r,\Theta}(r,\Theta) dr d\theta=p(x,y)\,dxdy$ we get $p_{r,\Theta}=p(x,y)r.$ Then $p(x,y)=\frac{1}{2\pi\sigma^{2}} e^{-r^{2}/2\sigma^{2}}$ so $p_{r,\Theta}=\frac{r}{2\pi\sigma^{2}} e^{-r^{2}/2\sigma^{2}}.$

By symmetry, since the joint is independent of $\Theta,$ we get $p_{\Theta}=\frac{1}{2\pi}.$

Finally, the marginal in $r$ is the joint multiplied by $2\pi$ i.e. $p_{r}=\frac{r}{\sigma^{2}} e^{-r^{2}/2\sigma^{2}}.$

# Problem 1.3
### (a)
The decision rule is based on the likelihood ratio. Likelihood for $H_{0}$ is $\frac{{\mathbb 1_{[-1,1]}(y)}}{2}\cdot \frac{1}{\sqrt{ \frac{\pi}{2} }}e^{-2z^{2}}$ and for $H_{1}$ is $\frac{{\mathbb 1_{[-2,2]}(y)}}{4}\cdot \frac{1}{\sqrt{ \frac{\pi}{2} }}e^{-2(z-1)^{2}}.$ The ratio is then
$$
\frac{p(H_{0}|y,z)}{p(H_{1}|y,z)}= \frac{{2\mathbb 1_{[-1,1]}(y)}}{\mathbb 1_{{[-2,2]}}(y)} \cdot e^{-2(2z-1)}.
$$
Then:
1. $y$ is always in $[-2,2].$ If $y\not\in [-1,1]$ then we must have $H_{1}$.
2. Otherwise the likelihood ratio is $2e^{2-4z},$ so we get $H_{0}$ if $z\leq \frac{{1+\ln_{}2}}{2}$ and $H_{1}$ otherwise.
### (b)
If the truth is $H_{0}$ then probability of error is equal to $z\geq \frac{{1+\ln2}}{2}$ i.e. $Q(1+\ln_{2})$ and if the truth is $H_{1}$ then probability of error is equal to $y \in [-1,1]$ and $z\leq \frac{{1+\ln2}}{2}$ i.e. $\frac{1}{2} Q(1-\ln2),$ hence the total probability of error is
$$
\frac{1}{2}Q(1+\ln 2)+\frac{1}{4}Q(1-\ln2).
$$
## Problem 1.4
### (a)
Since they're generated independently, the coin flip is "arbitrary" and opening the second envelope is equivalent to sampling from the PDF again. Then you switch envelopes if and only if the amount of money in the first envelope is less than the median of the PDF.
### (b)
Sample a random number $z$ from the normal Gaussian. Then switch envelopes if the envelope you open has money less than $z,$ and keep otherwise.
- If both envelopes have less than $z$ before you flip the coin, then this strategy doesn't change the likelihood of winning.
- Similarly if both have more than $z$ this strategy doesn't change the likelihood of winning.
- However if one envelope has more than $z$ and the other has less than $z$ then this strategy guarantees you win.
Since there is a nonzero probability of drawing some $z$ in between the values contained in the two envelopes, this strategy yields a strictly better than half chance of winning.