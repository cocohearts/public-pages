Better than MLPs, specifically for images.

Big matrix applied around a point, note that coordinates are *not* reversed unlike actual coordinates.
### five ways of seeing
- translation equivariance
- patch processing
- image (signal, wtv.) local filter (akin to e.g. local inverse fourier)
- sparse mlp matrix
- process variable-size tensors
### conv tricks
Can *pool* in the traditional way (pool 3x3 into single pixel) or also across *channels*. E.g. if we have a linear boundary detection filter at various orientations, but then pool over all these orientations. Note that pooling usually *doesn't downsample*, purpose is to increase stability. Can do max pool, mean pool, etc.

We do *strides*, which reduces the overlap between patches.

We can do *dilation*, which "spreads out" the convolution. We can get bigger patches for the same price.

So we can have this complicated formula for 2D convnets in terms of stride $s$, in channels $c_{i}$, out channels $c_{o}$, pooling patch side length $p$, kernel side length $k$, and dilation $d$.
### encoder-decoder model
Increase channel count as conv-layers are applied, compress into a representation. Then upsample, decreasing channel count and increasing resolution.

Precise spatial information is lost, so resnet the "reflected" channel information to the symmetric "other side" of the network. This way information sees more information at the same "level".
### applications
Can convolve across:
- time
- *direction* (for 3D reps)
As with any other model, if we want to *not* be location equivariant we can pass in coordinates to the layer.