Recall:
- insert
- pop min
Current approach:
- Binary-order HOTs
- Compare only if same degree (*union by rank*, referring to # children per root)

Then we get a *binomial tree*—with $2^{n}$ nodes, root has $n$ children each root for a $2^{i}$ binomial tree.

This collection of binomial trees forms a *binomial heap*. Insertion, merging are all amortized $O(1)$ (creating new 1-node trees lazily) and min deletion is amortized $O(\log n)$.
### Decrease Key
We want to cut a node, promote to root, rewrite its value.
The $2^{k}$ invariant is softened a little bit—nodes can only ever lose one child. If a node loses two children then it is also cut from its parent, and we keep going.
If the entire path up to root has all already been cut once, then we get lots of cutting.

Now we set $\phi=2\cdot n_{marked}+n_{roots}$. Then when we *delete key*, in the case of no cut $\phi \mathrel{+}=3$, in the case of parent cut we get an extra operation and extra root but $n_{marked}$ went down by 2. In this way, amortized is $O(1)$.

### Fibonacci naming
If size of tree of order $n$ is $S_{n}$ then the worst case is
$$
S_{n}=\sum ^{n-2}S_{i}.
$$
Given $S_{1}=1$ and $S_{2}=2$ we get $S_{n}=F_{n}$, the Fibonacci numbers.

The marking and cascading cut strategy is called *Saving Private Ryan*.
## Practical considerations
Binary heap is just *flat*—there's no auxiliary stuff, no pointers. Fibonacci heap is not a full binary tree so have to do tree pointer manipulation, which is not cache friendly.
## Back to MST
Prim's says: grow a single tree.
Kruskal's says: grab edges repeatedly.

The $\log n$ cost comes from having a large heap—what if every time our current tree gets big, what if we just hop to another node and start again? Let's make trees of size $k$ and then contract them into a single super-node.

We can just use $k\approx 2^{m/t}$, since our cost is $m+t\log k$. After every phase we divide $t$ by $k$, so $k'=2^{m/tk}=k2^{k}\approx 2^{k}$, so we get power tower ($\log ^*$) number of phases.