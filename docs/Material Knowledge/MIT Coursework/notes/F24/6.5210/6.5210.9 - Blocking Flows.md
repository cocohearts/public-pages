Better than Edmonds-Karp, we can say more.
### Admissible Paths
Do BFS to get distance of all nodes, arrange into "layers". *Admissible edges* are those pass "forward". The set of shortest paths $s\to t$ is all paths composed only of admissible edges.

We can try to "batch" our AP strategy by considering entire flows.
### Blocking Flows

> [!important] Blocking Flows
> Call a *blocking flow* one that *saturates* every admissible path. Then $d(s,t)$ increases after augmentation.

The augmenting path creates new arcs, but they only point backwards. The only possible new paths include a backwards arc, i.e. cannot be same length as the one that was added.

### Finding BFs
Act greedily.

> [!i] Greedy Blocking Flows
> - DFS from $s$ to $t$ along an admissible path and *saturate*, blocking the current path
> - Every time we dead-end, backtrack and *prune*
> - Repeat until *stopped*

Try a *unit-capacity graph*. For capacity $c$ replace with $c$ parallel edges. Advance and prune together is $O(m)$ and every edge is one or the other, so total cost for runtime is $O(mn)$.

In the general case, a block might only destroy one edge instead of all edges along the advance, so we need to do $O(mn)$ work to find a BF. Then we get $O(mn^{2}),$ already better than Edmonds-Karp.

A sexier trick we could use is *scaling*. When we scale we just get unit capacity graph $\log U$ times, so our runtime is $O(mn\log U).$
### Sleator-Tarjan Brilliancy
We spent work augmenting edges that weren't saturated, i.e. advanced across edges multiple times. Instead, we want a DS satisfying
- keep pieces of admissible paths
- Link root of tree to node of another (advance)
- Cut links by retreating, going back to root
- Decrease capacity
- Get min
Use Link-Cut trees, all above ops are $O(\log n)$. Then every edge is processed once so finding BF is $O(m\log n)$ yielding $O(mn\log n)$ runtime.

Then there's continuous optimization with electric flow and grad. descent. Then there's Y. Liu's '22 "Almost Linear" paper. Crazy guy.
